{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted closing value of the stock for 23-05-31 is: 3316.0008248495164\n",
      "The predicted closing value of the stock for 23-06-01 is: 3315.8022609680515\n",
      "The predicted closing value of the stock for 23-06-02 is: 3315.6042577679364\n",
      "The predicted closing value of the stock for 23-06-03 is: 3315.406813665985\n",
      "The predicted closing value of the stock for 23-06-04 is: 3315.209927083481\n",
      "The predicted closing value of the stock for 23-06-05 is: 3315.013596446167\n",
      "The predicted closing value of the stock for 23-06-06 is: 3314.81782018423\n",
      "The predicted closing value of the stock for 23-06-07 is: 3314.6225967322907\n",
      "The predicted closing value of the stock for 23-06-08 is: 3314.4279245293883\n",
      "The predicted closing value of the stock for 23-06-09 is: 3314.233802018971\n",
      "The predicted closing value of the stock for 23-06-10 is: 3314.0402276488817\n",
      "The predicted closing value of the stock for 23-06-11 is: 3313.847199871346\n",
      "The predicted closing value of the stock for 23-06-12 is: 3313.6547171429606\n",
      "The predicted closing value of the stock for 23-06-13 is: 3313.4627779246794\n",
      "The predicted closing value of the stock for 23-06-14 is: 3313.2713806818024\n",
      "The predicted closing value of the stock for 23-06-15 is: 3313.0805238839635\n",
      "The predicted closing value of the stock for 23-06-16 is: 3312.8902060051173\n",
      "The predicted closing value of the stock for 23-06-17 is: 3312.7004255235274\n",
      "The predicted closing value of the stock for 23-06-18 is: 3312.511180921755\n",
      "The predicted closing value of the stock for 23-06-19 is: 3312.322470686646\n",
      "The predicted closing value of the stock for 23-06-20 is: 3312.134293309318\n",
      "The predicted closing value of the stock for 23-06-21 is: 3311.9466472851495\n",
      "The predicted closing value of the stock for 23-06-22 is: 3311.759531113769\n",
      "The predicted closing value of the stock for 23-06-23 is: 3311.5729432990393\n",
      "The predicted closing value of the stock for 23-06-24 is: 3311.3868823490498\n",
      "The predicted closing value of the stock for 23-06-25 is: 3311.2013467761017\n",
      "The predicted closing value of the stock for 23-06-26 is: 3311.016335096697\n",
      "The predicted closing value of the stock for 23-06-27 is: 3310.831845831526\n",
      "The predicted closing value of the stock for 23-06-28 is: 3310.647877505458\n",
      "The predicted closing value of the stock for 23-06-29 is: 3310.4644286475254\n",
      "The predicted closing value of the stock for 23-06-30 is: 3310.2814977909156\n",
      "The predicted closing value of the stock for 23-07-01 is: 3310.0990834729573\n",
      "The predicted closing value of the stock for 23-07-02 is: 3309.9171842351093\n",
      "The predicted closing value of the stock for 23-07-03 is: 3309.735798622949\n",
      "The predicted closing value of the stock for 23-07-04 is: 3309.5549251861603\n",
      "The predicted closing value of the stock for 23-07-05 is: 3309.374562478523\n",
      "The predicted closing value of the stock for 23-07-06 is: 3309.1947090578997\n",
      "The predicted closing value of the stock for 23-07-07 is: 3309.015363486226\n",
      "The predicted closing value of the stock for 23-07-08 is: 3308.8365243294975\n",
      "The predicted closing value of the stock for 23-07-09 is: 3308.6581901577592\n",
      "The predicted closing value of the stock for 23-07-10 is: 3308.480359545094\n",
      "The predicted closing value of the stock for 23-07-11 is: 3308.303031069611\n",
      "The predicted closing value of the stock for 23-07-12 is: 3308.126203313434\n",
      "The predicted closing value of the stock for 23-07-13 is: 3307.949874862691\n",
      "The predicted closing value of the stock for 23-07-14 is: 3307.7740443075018\n",
      "The predicted closing value of the stock for 23-07-15 is: 3307.598710241967\n",
      "The predicted closing value of the stock for 23-07-16 is: 3307.4238712641586\n",
      "The predicted closing value of the stock for 23-07-17 is: 3307.2495259761054\n",
      "The predicted closing value of the stock for 23-07-18 is: 3307.075672983784\n",
      "The predicted closing value of the stock for 23-07-19 is: 3306.902310897108\n",
      "The predicted closing value of the stock for 23-07-20 is: 3306.7294383299154\n",
      "The predicted closing value of the stock for 23-07-21 is: 3306.557053899959\n",
      "The predicted closing value of the stock for 23-07-22 is: 3306.385156228894\n",
      "The predicted closing value of the stock for 23-07-23 is: 3306.213743942268\n",
      "The predicted closing value of the stock for 23-07-24 is: 3306.0428156695098\n",
      "The predicted closing value of the stock for 23-07-25 is: 3305.8723700439173\n",
      "The predicted closing value of the stock for 23-07-26 is: 3305.7024057026483\n",
      "The predicted closing value of the stock for 23-07-27 is: 3305.5329212867086\n",
      "The predicted closing value of the stock for 23-07-28 is: 3305.363915440942\n",
      "The predicted closing value of the stock for 23-07-29 is: 3305.195386814018\n",
      "The predicted closing value of the stock for 23-07-30 is: 3305.027334058422\n",
      "The predicted closing value of the stock for 23-07-31 is: 3304.8597558304446\n",
      "The predicted closing value of the stock for 23-08-01 is: 3304.6926507901703\n",
      "The predicted closing value of the stock for 23-08-02 is: 3304.5260176014676\n",
      "The predicted closing value of the stock for 23-08-03 is: 3304.359854931977\n",
      "The predicted closing value of the stock for 23-08-04 is: 3304.1941614531024\n",
      "The predicted closing value of the stock for 23-08-05 is: 3304.0289358399978\n",
      "The predicted closing value of the stock for 23-08-06 is: 3303.864176771559\n",
      "The predicted closing value of the stock for 23-08-07 is: 3303.699882930412\n",
      "The predicted closing value of the stock for 23-08-08 is: 3303.536053002903\n",
      "The predicted closing value of the stock for 23-08-09 is: 3303.3726856790868\n",
      "The predicted closing value of the stock for 23-08-10 is: 3303.2097796527178\n",
      "The predicted closing value of the stock for 23-08-11 is: 3303.0473336212385\n",
      "The predicted closing value of the stock for 23-08-12 is: 3302.885346285769\n",
      "The predicted closing value of the stock for 23-08-13 is: 3302.723816351098\n",
      "The predicted closing value of the stock for 23-08-14 is: 3302.5627425256703\n",
      "The predicted closing value of the stock for 23-08-15 is: 3302.4021235215782\n",
      "The predicted closing value of the stock for 23-08-16 is: 3302.241958054551\n",
      "The predicted closing value of the stock for 23-08-17 is: 3302.082244843944\n",
      "The predicted closing value of the stock for 23-08-18 is: 3301.9229826127284\n",
      "The predicted closing value of the stock for 23-08-19 is: 3301.7641700874824\n",
      "The predicted closing value of the stock for 23-08-20 is: 3301.6058059983784\n",
      "The predicted closing value of the stock for 23-08-21 is: 3301.447889079175\n",
      "The predicted closing value of the stock for 23-08-22 is: 3301.290418067207\n",
      "The predicted closing value of the stock for 23-08-23 is: 3301.133391703374\n",
      "The predicted closing value of the stock for 23-08-24 is: 3300.97680873213\n",
      "The predicted closing value of the stock for 23-08-25 is: 3300.8206679014756\n",
      "The predicted closing value of the stock for 23-08-26 is: 3300.6649679629463\n",
      "The predicted closing value of the stock for 23-08-27 is: 3300.509707671603\n",
      "The predicted closing value of the stock for 23-08-28 is: 3300.354885786021\n",
      "The predicted closing value of the stock for 23-08-29 is: 3300.200501068282\n",
      "The predicted closing value of the stock for 23-08-30 is: 3300.0465522839627\n",
      "The predicted closing value of the stock for 23-08-31 is: 3299.893038202126\n",
      "The predicted closing value of the stock for 23-09-01 is: 3299.7399575953095\n",
      "The predicted closing value of the stock for 23-09-02 is: 3299.5873092395177\n",
      "The predicted closing value of the stock for 23-09-03 is: 3299.435091914211\n",
      "The predicted closing value of the stock for 23-09-04 is: 3299.2833044022964\n",
      "The predicted closing value of the stock for 23-09-05 is: 3299.131945490117\n",
      "The predicted closing value of the stock for 23-09-06 is: 3298.981013967443\n",
      "The predicted closing value of the stock for 23-09-07 is: 3298.830508627462\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the OHLC data\n",
    "df = pd.read_csv('5y.csv')\n",
    "\n",
    "# Extract the input (X) and output (y) variables for prediction\n",
    "X = df[['Close']].drop(df.index[-1])  # input variable is the 'Close' column of OHLC data excluding the last row\n",
    "y = df[['Close']].drop(df.index[0])   # output variable is the 'Close' column of OHLC data excluding the first row\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the linear regression model on the training data\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Prompt the user for the number of days to predict\n",
    "n_days = int(input('Enter the number of days to predict: '))\n",
    "\n",
    "# Predict the closing value of the stock for the next n days\n",
    "last_close = df['Close'].iloc[-1]  # use the last row of the OHLC data to get the most recent closing value\n",
    "last_date = datetime.strptime(df['Date'].tail(1).values[0], '%m-%d-%Y')  # use the date of the last row of the OHLC data as the starting date\n",
    "for i in range(n_days):\n",
    "    next_close = lr.predict([[last_close]])[0][0]  # use the linear regression model to predict the next closing value\n",
    "    next_date = last_date + timedelta(days=i+1)  # compute the next date\n",
    "    print('The predicted closing value of the stock for', next_date.strftime('%y-%m-%d'), 'is:', next_close)\n",
    "    last_close = next_close  # update the last close value for the next iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to lr.csv file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the OHLC data\n",
    "df = pd.read_csv('5y.csv')\n",
    "\n",
    "# Extract the input (X) and output (y) variables for prediction\n",
    "X = df[['Close']].drop(df.index[-1])  # input variable is the 'Close' column of OHLC data excluding the last row\n",
    "y = df[['Close']].drop(df.index[0])   # output variable is the 'Close' column of OHLC data excluding the first row\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the linear regression model on the training data\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Prompt the user for the number of days to predict\n",
    "n_days = min(int(input('Enter the number of days to predict: ')), 100)  # Limit the number of days to 100\n",
    "\n",
    "# Predict the closing value of the stock for the next n days\n",
    "last_close = df['Close'].iloc[-1]  # use the last row of the OHLC data to get the most recent closing value\n",
    "last_date = datetime.strptime(df['Date'].tail(1).values[0], '%m-%d-%Y')  # use the date of the last row of the OHLC data as the starting date\n",
    "\n",
    "predictions = []  # Store the predictions\n",
    "\n",
    "for i in range(n_days):\n",
    "    next_close = lr.predict([[last_close]])[0][0]  # use the linear regression model to predict the next closing value\n",
    "    next_date = last_date + timedelta(days=i+1)  # compute the next date\n",
    "    predictions.append([next_date.strftime('%y-%m-%d'), next_close])  # store the prediction\n",
    "    last_close = next_close  # update the last close value for the next iteration\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Date', 'Predicted Closing Value'])\n",
    "predictions_df.to_csv('lr.csv', index=False)\n",
    "\n",
    "print('Predictions saved to lr.csv file.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp/ipykernel_23292/1070891471.py:18: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to rfr.csv file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the OHLC data\n",
    "df = pd.read_csv('5y.csv')\n",
    "\n",
    "# Extract the input (X) and output (y) variables for prediction\n",
    "X = df[['Close']].drop(df.index[-1])  # input variable is the 'Close' column of OHLC data excluding the last row\n",
    "y = df[['Close']].drop(df.index[0])   # output variable is the 'Close' column of OHLC data excluding the first row\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the Random Forest Regressor model on the training data\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Prompt the user for the number of days to predict\n",
    "n_days = int(input('Enter the number of days to predict: '))\n",
    "\n",
    "# Predict the closing value of the stock for the next n days\n",
    "last_close = df['Close'].iloc[-1]  # use the last row of the OHLC data to get the most recent closing value\n",
    "last_date = datetime.strptime(df['Date'].tail(1).values[0], '%m-%d-%Y')  # use the date of the last row of the OHLC data as the starting date\n",
    "\n",
    "predictions = []  # Store the predictions\n",
    "\n",
    "for i in range(n_days):\n",
    "    next_close = rf.predict([[last_close]])[0]  # use the Random Forest Regressor model to predict the next closing value\n",
    "    next_date = last_date + timedelta(days=i+1)  # compute the next date\n",
    "    predictions.append([next_date.strftime('%y-%m-%d'), next_close])  # store the prediction\n",
    "    last_close = next_close  # update the last close value for the next iteration\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Date', 'Predicted Closing Value'])\n",
    "predictions_df.to_csv('rfr.csv', index=False)\n",
    "\n",
    "print('Predictions saved to rfr.csv file.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to dtr.csv file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the OHLC data\n",
    "df = pd.read_csv('5y.csv')\n",
    "\n",
    "# Extract the input (X) and output (y) variables for prediction\n",
    "X = df[['Close']].drop(df.index[-1])  # input variable is the 'Close' column of OHLC data excluding the last row\n",
    "y = df[['Close']].drop(df.index[0])   # output variable is the 'Close' column of OHLC data excluding the first row\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the Decision Tree Regressor model on the training data\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Prompt the user for the number of days to predict\n",
    "n_days = int(input('Enter the number of days to predict: '))\n",
    "\n",
    "# Predict the closing value of the stock for the next n days\n",
    "last_close = df['Close'].iloc[-1]  # use the last row of the OHLC data to get the most recent closing value\n",
    "last_date = datetime.strptime(df['Date'].tail(1).values[0], '%m-%d-%Y')  # use the date of the last row of the OHLC data as the starting date\n",
    "\n",
    "predictions = []  # Store the predictions\n",
    "\n",
    "for i in range(n_days):\n",
    "    next_close = dt.predict([[last_close]])[0]  # use the Decision Tree Regressor model to predict the next closing value\n",
    "    next_date = last_date + timedelta(days=i+1)  # compute the next date\n",
    "    predictions.append([next_date.strftime('%y-%m-%d'), next_close])  # store the prediction\n",
    "    last_close = next_close  # update the last close value for the next iteration\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Date', 'Predicted Closing Value'])\n",
    "predictions_df.to_csv('dtr.csv', index=False)\n",
    "\n",
    "print('Predictions saved to dtr.csv file.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to nn.csv file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the OHLC data\n",
    "df = pd.read_csv('5y.csv')\n",
    "\n",
    "# Extract the input (X) and output (y) variables for prediction\n",
    "X = df[['Close']].drop(df.index[-1])  # input variable is the 'Close' column of OHLC data excluding the last row\n",
    "y = df[['Close']].drop(df.index[0])   # output variable is the 'Close' column of OHLC data excluding the first row\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the MLP Regressor model on the training data\n",
    "mlp = MLPRegressor()\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Prompt the user for the number of days to predict\n",
    "n_days = int(input('Enter the number of days to predict: '))\n",
    "\n",
    "# Predict the closing value of the stock for the next n days\n",
    "last_close = df['Close'].iloc[-1]  # use the last row of the OHLC data to get the most recent closing value\n",
    "last_date = datetime.strptime(df['Date'].tail(1).values[0], '%m-%d-%Y')  # use the date of the last row of the OHLC data as the starting date\n",
    "\n",
    "predictions = []  # Store the predictions\n",
    "\n",
    "for i in range(n_days):\n",
    "    next_close = mlp.predict([[last_close]])[0]  # use the MLP Regressor model to predict the next closing value\n",
    "    next_date = last_date + timedelta(days=i+1)  # compute the next date\n",
    "    predictions.append([next_date.strftime('%y-%m-%d'), next_close])  # store the prediction\n",
    "    last_close = next_close  # update the last close value for the next iteration\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Date', 'Predicted Closing Value'])\n",
    "predictions_df.to_csv('nn.csv', index=False)\n",
    "\n",
    "print('Predictions saved to nn.csv file.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "986/986 - 3s - loss: 7725506.5000 - 3s/epoch - 3ms/step\n",
      "Epoch 2/50\n",
      "986/986 - 1s - loss: 7429085.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 3/50\n",
      "986/986 - 1s - loss: 7184853.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "986/986 - 1s - loss: 6972588.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 5/50\n",
      "986/986 - 1s - loss: 6774633.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 6/50\n",
      "986/986 - 1s - loss: 6585246.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 7/50\n",
      "986/986 - 1s - loss: 6401565.0000 - 1s/epoch - 1ms/step\n",
      "Epoch 8/50\n",
      "986/986 - 1s - loss: 6222338.0000 - 1s/epoch - 1ms/step\n",
      "Epoch 9/50\n",
      "986/986 - 1s - loss: 6046655.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 10/50\n",
      "986/986 - 1s - loss: 5874575.0000 - 1s/epoch - 1ms/step\n",
      "Epoch 11/50\n",
      "986/986 - 1s - loss: 5705967.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 12/50\n",
      "986/986 - 2s - loss: 5539980.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 13/50\n",
      "986/986 - 1s - loss: 5376761.0000 - 1s/epoch - 1ms/step\n",
      "Epoch 14/50\n",
      "986/986 - 1s - loss: 5216711.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 15/50\n",
      "986/986 - 1s - loss: 5059750.0000 - 1s/epoch - 1ms/step\n",
      "Epoch 16/50\n",
      "986/986 - 1s - loss: 4905783.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 17/50\n",
      "986/986 - 1s - loss: 4754582.0000 - 1s/epoch - 1ms/step\n",
      "Epoch 18/50\n",
      "986/986 - 1s - loss: 4606123.5000 - 1s/epoch - 2ms/step\n",
      "Epoch 19/50\n",
      "986/986 - 1s - loss: 4460495.0000 - 1s/epoch - 1ms/step\n",
      "Epoch 20/50\n",
      "986/986 - 1s - loss: 4317983.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 21/50\n",
      "986/986 - 1s - loss: 4178394.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 22/50\n",
      "986/986 - 1s - loss: 4041524.2500 - 1s/epoch - 1ms/step\n",
      "Epoch 23/50\n",
      "986/986 - 1s - loss: 3907360.7500 - 1s/epoch - 1ms/step\n",
      "Epoch 24/50\n",
      "986/986 - 1s - loss: 3776104.7500 - 1s/epoch - 1ms/step\n",
      "Epoch 25/50\n",
      "986/986 - 1s - loss: 3648206.0000 - 1s/epoch - 1ms/step\n",
      "Epoch 26/50\n",
      "986/986 - 1s - loss: 3522892.2500 - 1s/epoch - 1ms/step\n",
      "Epoch 27/50\n",
      "986/986 - 1s - loss: 3400369.0000 - 1s/epoch - 1ms/step\n",
      "Epoch 28/50\n",
      "986/986 - 1s - loss: 3280468.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 29/50\n",
      "986/986 - 1s - loss: 3163462.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 30/50\n",
      "986/986 - 1s - loss: 3049285.7500 - 1s/epoch - 1ms/step\n",
      "Epoch 31/50\n",
      "986/986 - 1s - loss: 2938167.7500 - 1s/epoch - 1ms/step\n",
      "Epoch 32/50\n",
      "986/986 - 1s - loss: 2829854.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 33/50\n",
      "986/986 - 1s - loss: 2724603.7500 - 1s/epoch - 1ms/step\n",
      "Epoch 34/50\n",
      "986/986 - 1s - loss: 2621967.0000 - 1s/epoch - 1ms/step\n",
      "Epoch 35/50\n",
      "986/986 - 1s - loss: 2521583.0000 - 1s/epoch - 1ms/step\n",
      "Epoch 36/50\n",
      "986/986 - 1s - loss: 2424138.7500 - 1s/epoch - 1ms/step\n",
      "Epoch 37/50\n",
      "986/986 - 1s - loss: 2329898.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 38/50\n",
      "986/986 - 1s - loss: 2238258.2500 - 1s/epoch - 1ms/step\n",
      "Epoch 39/50\n",
      "986/986 - 1s - loss: 2149074.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 40/50\n",
      "986/986 - 1s - loss: 2062837.0000 - 1s/epoch - 1ms/step\n",
      "Epoch 41/50\n",
      "986/986 - 1s - loss: 1979508.3750 - 1s/epoch - 1ms/step\n",
      "Epoch 42/50\n",
      "986/986 - 1s - loss: 1898803.1250 - 1s/epoch - 1ms/step\n",
      "Epoch 43/50\n",
      "986/986 - 1s - loss: 1820553.1250 - 1s/epoch - 1ms/step\n",
      "Epoch 44/50\n",
      "986/986 - 1s - loss: 1745396.0000 - 1s/epoch - 1ms/step\n",
      "Epoch 45/50\n",
      "986/986 - 1s - loss: 1672866.7500 - 1s/epoch - 1ms/step\n",
      "Epoch 46/50\n",
      "986/986 - 1s - loss: 1602725.6250 - 1s/epoch - 1ms/step\n",
      "Epoch 47/50\n",
      "986/986 - 1s - loss: 1535282.8750 - 1s/epoch - 1ms/step\n",
      "Epoch 48/50\n",
      "986/986 - 1s - loss: 1470700.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 49/50\n",
      "986/986 - 1s - loss: 1408575.5000 - 1s/epoch - 1ms/step\n",
      "Epoch 50/50\n",
      "986/986 - 1s - loss: 1348846.6250 - 1s/epoch - 1ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predictions saved to lstm.csv file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the OHLC data\n",
    "df = pd.read_csv('5yr.csv')\n",
    "\n",
    "# Extract the input (X) and output (y) variables for prediction\n",
    "X = df[['Close']].drop(df.index[-1])  # input variable is the 'Close' column of OHLC data excluding the last row\n",
    "y = df[['Close']].drop(df.index[0])   # output variable is the 'Close' column of OHLC data excluding the first row\n",
    "\n",
    "# Normalize the input data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(1, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=1, verbose=2)\n",
    "\n",
    "# Prompt the user for the number of days to predict\n",
    "n_days = int(input('Enter the number of days to predict: '))\n",
    "\n",
    "# Predict the closing value of the stock for the next n days\n",
    "last_close = df['Close'].iloc[-1]  # use the last row of the OHLC data to get the most recent closing value\n",
    "last_date = datetime.strptime(df['Date'].tail(1).values[0], '%m-%d-%Y')  # use the date of the last row of the OHLC data as the starting date\n",
    "\n",
    "predictions = []  # Store the predictions\n",
    "\n",
    "for i in range(n_days):\n",
    "    next_close_scaled = model.predict(np.array([[last_close]]))  # use the LSTM model to predict the next closing value\n",
    "    next_close = scaler.inverse_transform(next_close_scaled)[0][0]  # scale back the predicted value\n",
    "    next_date = last_date + timedelta(days=i+1)  # compute the next date\n",
    "    predictions.append([next_date.strftime('%y-%m-%d'), next_close])  # store the prediction\n",
    "    last_close = next_close  # update the last close value for the next iteration\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Date', 'Predicted Closing Value'])\n",
    "predictions_df.to_csv('lstm.csv', index=False)\n",
    "\n",
    "print('Predictions saved to lstm.csv file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
